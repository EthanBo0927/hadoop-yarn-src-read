# Hadoop YARN RPC 使用 protocol buffer #

----------

### 中心思想 ###

前面已经实现了 hadoop 的 RPC 框架，然后我们想用 `ResourceTracker` 协议通信。做法是，使用 `protocol buffer` 定义的 `RPC service`，让 PB 作为序列化层，完成序列化工作后，调用 `real` 的成员去真正调用 `ResourceTracker`协议的方法。 `real` 是`ResourceTracker`协议的真正实现，它通过配置文件被注入到 PB 的 协议实现里。

下面用看具体步骤：

在YARN中，`ResourceManager` 和 `NodeManager` 之间的通信协议是 `ResourceTracker`，其中NodeManager是该协议的客户端，ResourceManager是服务端，NodeManager通过该协议中定义的两个RPC函数（`registerNodeManager` 和 `nodeHeartbeat`）向ResourceManager注册和周期性发送心跳信息。

----------

### 一、 定义通信协议接口 `ResourceTracker` ###

	public interface ResourceTracker {  
	  public RegisterNodeManagerResponse registerNodeManager(  
	      RegisterNodeManagerRequest request) throws YarnException, IOException;  
	  public NodeHeartbeatResponse nodeHeartbeat(NodeHeartbeatRequest request)  
	      throws YarnException, IOException;  
	} 

----------

### 二、为通信协议 `ResourceTracker` 提供 Protocol Buffers 定义和 Java 实现 ###

#### 1、service proto 文件 ####

	option java_package = "org.apache.hadoop.yarn.proto";  
	option java_outer_classname = "ResourceTracker";  
	option java_generic_services = true;  //注意这行，PB定义协议
	option java_generate_equals_and_hash = true;  
	import "yarn_server_common_service_protos.proto"; //导入一些PB定义的字段
	 
	service ResourceTrackerService {  
	  rpc registerNodeManager(RegisterNodeManagerRequestProto) returns (RegisterNodeManagerResponseProto);  
	  rpc nodeHeartbeat(NodeHeartbeatRequestProto) returns (NodeHeartbeatResponseProto);  
	}

#### 2、参数的 proto 文件 ####

上面的请求参数和返回参数等没有定义，需要导入定义，在文件 `yarn_server_common_service_protos.proto` 里面：

	import "yarn_protos.proto";  
	import "yarn_server_common_protos.proto";  
	 
	message RegisterNodeManagerRequestProto {  
	  optional NodeIdProto node_id = 1;  
	  optional int32 http_port = 3;  
	  optional ResourceProto resource = 4;  
	}  
	 
	message RegisterNodeManagerResponseProto {  
	  optional MasterKeyProto container_token_master_key = 1;  
	  optional MasterKeyProto nm_token_master_key = 2;  
	  optional NodeActionProto nodeAction = 3;  
	  optional int64 rm_identifier = 4;  
	  optional string diagnostics_message = 5;  
	}  
	... //其他几个参数和返回值的定义 

#### 3、编译后的 Service 类 ####

编译上面的 Service proto 文件。注意：

1. 外面的 `ResourceTracker` 是包装类。
2. 里面的`ResourceTrackerService`是proto文件定义的 RPC Service，里面有定义的 RPC 方法，不过是抽象的abstract。
3. `ResourceTrackerService.Interface`接口有 proto文件定义的RPC 方法。内部类`Stub`实现了这个接口，而且继承了`ResourceTrackerService`类。`BlockingInterface`接口类似。
4. `ResourceTrackerService#newReflectiveService(impl)` 和 `ResourceTrackerService#newReflectiveBlockingService(impl)` 两个方法是真正实现，它们会调用 真正的协议实现类的实例impl 去完成RPC请求。

编译后的Service类 `org.apache.hadoop.yarn.proto.ResourceTracker`：

	// Generated by the protocol buffer compiler.  DO NOT EDIT!
	// source: ResourceTracker.proto
	
	package org.apache.hadoop.yarn.proto;
	
	public final class ResourceTracker {
	  private ResourceTracker() {}
	  public static void registerAllExtensions(
	      com.google.protobuf.ExtensionRegistry registry) {
	  }
	  /**
	   * Protobuf service {@code hadoop.yarn.ResourceTrackerService}
	   */
	  public static abstract class ResourceTrackerService
	      implements com.google.protobuf.Service {
	    protected ResourceTrackerService() {}
	
	    public interface Interface {
	      /**
	       * <code>rpc registerNodeManager(.hadoop.yarn.RegisterNodeManagerRequestProto) returns (.hadoop.yarn.RegisterNodeManagerResponseProto);</code>
	       */
	      public abstract void registerNodeManager(
	          com.google.protobuf.RpcController controller,
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto request,
	          com.google.protobuf.RpcCallback<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto> done);
	
	      /**
	       * <code>rpc nodeHeartbeat(.hadoop.yarn.NodeHeartbeatRequestProto) returns (.hadoop.yarn.NodeHeartbeatResponseProto);</code>
	       */
	      public abstract void nodeHeartbeat(
	          com.google.protobuf.RpcController controller,
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto request,
	          com.google.protobuf.RpcCallback<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto> done);
	
	    }
	
	    public static com.google.protobuf.Service newReflectiveService(
	        final Interface impl) {
	      return new ResourceTrackerService() {
	        @java.lang.Override
	        public  void registerNodeManager(
	            com.google.protobuf.RpcController controller,
	            org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto request,
	            com.google.protobuf.RpcCallback<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto> done) {
	          impl.registerNodeManager(controller, request, done);
	        }
	
	        @java.lang.Override
	        public  void nodeHeartbeat(
	            com.google.protobuf.RpcController controller,
	            org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto request,
	            com.google.protobuf.RpcCallback<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto> done) {
	          impl.nodeHeartbeat(controller, request, done);
	        }
	
	      };
	    }
	
	    public static com.google.protobuf.BlockingService
	        newReflectiveBlockingService(final BlockingInterface impl) {
	      return new com.google.protobuf.BlockingService() {
	        public final com.google.protobuf.Descriptors.ServiceDescriptor
	            getDescriptorForType() {
	          return getDescriptor();
	        }
	
	        public final com.google.protobuf.Message callBlockingMethod(
	            com.google.protobuf.Descriptors.MethodDescriptor method,
	            com.google.protobuf.RpcController controller,
	            com.google.protobuf.Message request)
	            throws com.google.protobuf.ServiceException {
	          if (method.getService() != getDescriptor()) {
	            throw new java.lang.IllegalArgumentException(
	              "Service.callBlockingMethod() given method descriptor for " +
	              "wrong service type.");
	          }
	          switch(method.getIndex()) {
	            case 0:
	              return impl.registerNodeManager(controller, (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto)request);
	            case 1:
	              return impl.nodeHeartbeat(controller, (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto)request);
	            default:
	              throw new java.lang.AssertionError("Can't get here.");
	          }
	        }
	
	        public final com.google.protobuf.Message
	            getRequestPrototype(
	            com.google.protobuf.Descriptors.MethodDescriptor method) {
	          if (method.getService() != getDescriptor()) {
	            throw new java.lang.IllegalArgumentException(
	              "Service.getRequestPrototype() given method " +
	              "descriptor for wrong service type.");
	          }
	          switch(method.getIndex()) {
	            case 0:
	              return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto.getDefaultInstance();
	            case 1:
	              return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto.getDefaultInstance();
	            default:
	              throw new java.lang.AssertionError("Can't get here.");
	          }
	        }
	
	        public final com.google.protobuf.Message
	            getResponsePrototype(
	            com.google.protobuf.Descriptors.MethodDescriptor method) {
	          if (method.getService() != getDescriptor()) {
	            throw new java.lang.IllegalArgumentException(
	              "Service.getResponsePrototype() given method " +
	              "descriptor for wrong service type.");
	          }
	          switch(method.getIndex()) {
	            case 0:
	              return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.getDefaultInstance();
	            case 1:
	              return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.getDefaultInstance();
	            default:
	              throw new java.lang.AssertionError("Can't get here.");
	          }
	        }
	
	      };
	    }
	
	    /**
	     * <code>rpc registerNodeManager(.hadoop.yarn.RegisterNodeManagerRequestProto) returns (.hadoop.yarn.RegisterNodeManagerResponseProto);</code>
	     */
	    public abstract void registerNodeManager(
	        com.google.protobuf.RpcController controller,
	        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto request,
	        com.google.protobuf.RpcCallback<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto> done);
	
	    /**
	     * <code>rpc nodeHeartbeat(.hadoop.yarn.NodeHeartbeatRequestProto) returns (.hadoop.yarn.NodeHeartbeatResponseProto);</code>
	     */
	    public abstract void nodeHeartbeat(
	        com.google.protobuf.RpcController controller,
	        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto request,
	        com.google.protobuf.RpcCallback<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto> done);
	
	    public static final
	        com.google.protobuf.Descriptors.ServiceDescriptor
	        getDescriptor() {
	      return org.apache.hadoop.yarn.proto.ResourceTracker.getDescriptor().getServices().get(0);
	    }
	    public final com.google.protobuf.Descriptors.ServiceDescriptor
	        getDescriptorForType() {
	      return getDescriptor();
	    }
	
	    public final void callMethod(
	        com.google.protobuf.Descriptors.MethodDescriptor method,
	        com.google.protobuf.RpcController controller,
	        com.google.protobuf.Message request,
	        com.google.protobuf.RpcCallback<
	          com.google.protobuf.Message> done) {
	      if (method.getService() != getDescriptor()) {
	        throw new java.lang.IllegalArgumentException(
	          "Service.callMethod() given method descriptor for wrong " +
	          "service type.");
	      }
	      switch(method.getIndex()) {
	        case 0:
	          this.registerNodeManager(controller, (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto)request,
	            com.google.protobuf.RpcUtil.<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto>specializeCallback(
	              done));
	          return;
	        case 1:
	          this.nodeHeartbeat(controller, (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto)request,
	            com.google.protobuf.RpcUtil.<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto>specializeCallback(
	              done));
	          return;
	        default:
	          throw new java.lang.AssertionError("Can't get here.");
	      }
	    }
	
	    public final com.google.protobuf.Message
	        getRequestPrototype(
	        com.google.protobuf.Descriptors.MethodDescriptor method) {
	      if (method.getService() != getDescriptor()) {
	        throw new java.lang.IllegalArgumentException(
	          "Service.getRequestPrototype() given method " +
	          "descriptor for wrong service type.");
	      }
	      switch(method.getIndex()) {
	        case 0:
	          return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto.getDefaultInstance();
	        case 1:
	          return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto.getDefaultInstance();
	        default:
	          throw new java.lang.AssertionError("Can't get here.");
	      }
	    }
	
	    public final com.google.protobuf.Message
	        getResponsePrototype(
	        com.google.protobuf.Descriptors.MethodDescriptor method) {
	      if (method.getService() != getDescriptor()) {
	        throw new java.lang.IllegalArgumentException(
	          "Service.getResponsePrototype() given method " +
	          "descriptor for wrong service type.");
	      }
	      switch(method.getIndex()) {
	        case 0:
	          return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.getDefaultInstance();
	        case 1:
	          return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.getDefaultInstance();
	        default:
	          throw new java.lang.AssertionError("Can't get here.");
	      }
	    }
	
	    public static Stub newStub(
	        com.google.protobuf.RpcChannel channel) {
	      return new Stub(channel);
	    }
	
	    public static final class Stub extends org.apache.hadoop.yarn.proto.ResourceTracker.ResourceTrackerService implements Interface {
	      private Stub(com.google.protobuf.RpcChannel channel) {
	        this.channel = channel;
	      }
	
	      private final com.google.protobuf.RpcChannel channel;
	
	      public com.google.protobuf.RpcChannel getChannel() {
	        return channel;
	      }
	
	      public  void registerNodeManager(
	          com.google.protobuf.RpcController controller,
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto request,
	          com.google.protobuf.RpcCallback<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto> done) {
	        channel.callMethod(
	          getDescriptor().getMethods().get(0),
	          controller,
	          request,
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.getDefaultInstance(),
	          com.google.protobuf.RpcUtil.generalizeCallback(
	            done,
	            org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.class,
	            org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.getDefaultInstance()));
	      }
	
	      public  void nodeHeartbeat(
	          com.google.protobuf.RpcController controller,
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto request,
	          com.google.protobuf.RpcCallback<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto> done) {
	        channel.callMethod(
	          getDescriptor().getMethods().get(1),
	          controller,
	          request,
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.getDefaultInstance(),
	          com.google.protobuf.RpcUtil.generalizeCallback(
	            done,
	            org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.class,
	            org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.getDefaultInstance()));
	      }
	    }
	
	    public static BlockingInterface newBlockingStub(
	        com.google.protobuf.BlockingRpcChannel channel) {
	      return new BlockingStub(channel);
	    }
	
	    public interface BlockingInterface {
	      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto registerNodeManager(
	          com.google.protobuf.RpcController controller,
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto request)
	          throws com.google.protobuf.ServiceException;
	
	      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto nodeHeartbeat(
	          com.google.protobuf.RpcController controller,
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto request)
	          throws com.google.protobuf.ServiceException;
	    }
	
	    private static final class BlockingStub implements BlockingInterface {
	      private BlockingStub(com.google.protobuf.BlockingRpcChannel channel) {
	        this.channel = channel;
	      }
	
	      private final com.google.protobuf.BlockingRpcChannel channel;
	
	      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto registerNodeManager(
	          com.google.protobuf.RpcController controller,
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto request)
	          throws com.google.protobuf.ServiceException {
	        return (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto) channel.callBlockingMethod(
	          getDescriptor().getMethods().get(0),
	          controller,
	          request,
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.getDefaultInstance());
	      }
	
	
	      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto nodeHeartbeat(
	          com.google.protobuf.RpcController controller,
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto request)
	          throws com.google.protobuf.ServiceException {
	        return (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto) channel.callBlockingMethod(
	          getDescriptor().getMethods().get(1),
	          controller,
	          request,
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.getDefaultInstance());
	      }
	
	    }
	
	    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceTrackerService)
	  }
	
	
	  public static com.google.protobuf.Descriptors.FileDescriptor
	      getDescriptor() {
	    return descriptor;
	  }
	  private static com.google.protobuf.Descriptors.FileDescriptor
	      descriptor;
	  static {
	    java.lang.String[] descriptorData = {
	      "\n\025ResourceTracker.proto\022\013hadoop.yarn\032\'ya" +
	      "rn_server_common_service_protos.proto2\356\001" +
	      "\n\026ResourceTrackerService\022r\n\023registerNode" +
	      "Manager\022,.hadoop.yarn.RegisterNodeManage" +
	      "rRequestProto\032-.hadoop.yarn.RegisterNode" +
	      "ManagerResponseProto\022`\n\rnodeHeartbeat\022&." +
	      "hadoop.yarn.NodeHeartbeatRequestProto\032\'." +
	      "hadoop.yarn.NodeHeartbeatResponseProtoB5" +
	      "\n\034org.apache.hadoop.yarn.protoB\017Resource" +
	      "Tracker\210\001\001\240\001\001"
	    };
	    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
	      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
	        public com.google.protobuf.ExtensionRegistry assignDescriptors(
	            com.google.protobuf.Descriptors.FileDescriptor root) {
	          descriptor = root;
	          return null;
	        }
	      };
	    com.google.protobuf.Descriptors.FileDescriptor
	      .internalBuildGeneratedFileFrom(descriptorData,
	        new com.google.protobuf.Descriptors.FileDescriptor[] {
	          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.getDescriptor(),
	        }, assigner);
	  }
	
	  // @@protoc_insertion_point(outer_class_scope)
	}

#### 4、编译 参数 proto文件，生成对应的类 ####

这个代码就不贴了，很普通的。

生成类：`org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos`

----------

### 三、为RPC函数的参数和返回值提供Java定义和封装 ###

其实就是 对上面的`YarnServerCommonServiceProtos`类里面的字段进行进一步封装，为了更方便使用。

为RPC函数的参数和返回值提供Java定义和封装。YARN采用了Protocol Buffers作为参数和返回值的序列化框架，且以原生态.proto文件的方式给出了定义，而具体的Java代码生成需在代码编写之后完成。基于以上考虑，为了更容易使用Protocol Buffers生成的（Java语言）参数和返回值定义，YARN RPC为每个RPC函数的参数和返回值提供Java定义和封装，以参数RegisterNodeManagerRequest为例进行说明。

Java接口定义如下（见Java包 `org.apache.hadoop.yarn.server.api.protocolrecords`）：

	public interface RegisterNodeManagerRequest {  
	  NodeId getNodeId();  
	  int getHttpPort();  
	  Resource getResource();  
	 
	  void setNodeId(NodeId nodeId);  
	  void setHttpPort(int port);  
	  void setResource(Resource resource);  
	} 

Java封装如（见Java包 `org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb`：

	public class RegisterNodeManagerRequestPBImpl extends  
	  ProtoBase<RegisterNodeManagerRequestProto> implements RegisterNodeManagerRequest {  
	  RegisterNodeManagerRequestProto proto = RegisterNodeManagerRequestProto.getDefaultInstance();  
	  RegisterNodeManagerRequestProto.Builder builder = null;  
	  private NodeId nodeId = null;  
	  ...  
	  @Override  
	  public NodeId getNodeId() {  
	    RegisterNodeManagerRequestProtoOrBuilder p = viaProto ? proto : builder;  
	    if (this.nodeId != null) {  
	      return this.nodeId;  
	    }  
	    if (!p.hasNodeId()) {  
	      return null;  
	    }  
	    this.nodeId = convertFromProtoFormat(p.getNodeId());  
	    return this.nodeId;  
	  }  
	  @Override  
	  public void setNodeId(NodeId nodeId) {  
	    maybeInitBuilder();  
	    if (nodeId == null)  
	      builder.clearNodeId();  
	    this.nodeId = nodeId;  
	  }  
	  ...  
	} 

### 四、 ###

定义接口`org.apache.hadoop.yarn.server.api.ResourceTrackerPB`,继承的是的 PB 定义的Service 的 `BlockingInterface` 接口。

	public interface ResourceTrackerPB extends ResourceTrackerService.BlockingInterface {
	
	}

#### 1、服务器 PB 实现 ####

这个接口的实现`ResourceTrackerPBServiceImpl`：

注意real变量，会通过配置文件注入真正是协议实现类：YARN 的 `ResourceTrackerService`类。

它实现的是 `ResourceTrackerPB`接口，而不是yarn的`ResourceTracker`。

	public class ResourceTrackerPBServiceImpl implements ResourceTrackerPB {
	
	  private ResourceTracker real;//注意这个real变量，会通过配置文件注入真正是协议实现类
	  
	  public ResourceTrackerPBServiceImpl(ResourceTracker impl) {
	    this.real = impl;
	  }
	  
	  @Override
	  public RegisterNodeManagerResponseProto registerNodeManager(
	      RpcController controller, RegisterNodeManagerRequestProto proto)
	      throws ServiceException {
	    RegisterNodeManagerRequestPBImpl request = new RegisterNodeManagerRequestPBImpl(proto);
	    try {
	      RegisterNodeManagerResponse response = real.registerNodeManager(request);
	      return ((RegisterNodeManagerResponsePBImpl)response).getProto();
	    } catch (YarnException e) {
	      throw new ServiceException(e);
	    } catch (IOException e) {
	      throw new ServiceException(e);
	    }
	  }
	
	  @Override
	  public NodeHeartbeatResponseProto nodeHeartbeat(RpcController controller,
	      NodeHeartbeatRequestProto proto) throws ServiceException {
	    NodeHeartbeatRequestPBImpl request = new NodeHeartbeatRequestPBImpl(proto);
	    try {
	      NodeHeartbeatResponse response = real.nodeHeartbeat(request);
	      return ((NodeHeartbeatResponsePBImpl)response).getProto();
	    } catch (YarnException e) {
	      throw new ServiceException(e);
	    } catch (IOException e) {
	      throw new ServiceException(e);
	    }
	  }
	
	}

#### 2、客户端 PB 实现 ####

这里生成的是 `ResourceTrackerPB`协议的代理，而不是 YARN `ResourceTracker`协议的代理，跟上面服务器PB的实现不同。
	
	public class ResourceTrackerPBClientImpl implements ResourceTracker, Closeable {  
	  private ResourceTrackerPB proxy;  
	  public ResourceTrackerPBClientImpl(long clientVersion, InetSocketAddress addr, Configuration conf) throws IOException {  
	    RPC.setProtocolEngine(conf, ResourceTrackerPB.class, ProtobufRpcEngine.class);  
	    proxy = (ResourceTrackerPB)RPC.getProxy(  
	        ResourceTrackerPB.class, clientVersion, addr, conf);  
	  }  
	  @Override  
	  public RegisterNodeManagerResponse registerNodeManager(  
	      RegisterNodeManagerRequest request) throws YarnException,  
	      IOException {  
	    RegisterNodeManagerRequestProto requestProto = ((RegisterNodeManagerRequestPBImpl)request).getProto();  
	    try {  
	      return new RegisterNodeManagerResponsePBImpl(proxy.registerNodeManager (null, requestProto));  
	    } catch (ServiceException e) {  
	      RPCUtil.unwrapAndThrowException(e);  
	      return null;  
	    }  
	  }  
	  ...  
	} 

----------

### 五、YARN `ResourceTracker`协议的使用 ###

#### 1、服务器端 `ResourceTrackerService` ####

表面上，使用`ResourceTracker`协议和`ResourceTrackerService`实例生成了客户端，实际上是：

1. 利用 `ResourceTracker`协议名字，找到对应package下面的`ResourceTrackerPBServiceImpl`类。
2. 反射生成`ResourceTrackerPBServiceImpl`类的实例，把`ResourceTrackerService`实例作为构造方法的参数传入。也就是上面说的，把yarn `ResourceTracker`协议的实现类的实例注入到 PB 服务器 `ResourceTrackerPBServiceImpl`实例里面。
3. 利用`ResourceTrackerPBServiceImpl`实例找到它实现的协议接口 `ResourceTrackerPB`。
4. 用协议接口`ResourceTrackerPB`和`ResourceTrackerPBServiceImpl`实例生成RPC服务器，而这个RPC服务器使用的是PB序列化工具。

> 从整体上看，就是让 YARN 框架 以为使用 yarn的协议`ResourceTracker`和实例`ResourceTrackerService`生成了 RPC 服务器，而且这个服务器不需要考虑序列化的问题。
> 
> 而RPC框架知道，其实多加了PB序列化层，用反射实现，跟过滤器的实现原理非常像。框架生成的是 PB 的RPC服务器，服务器用PB序列化，真正的YARN框架逻辑交给内部实例impl去完成。这个内部实例就是`ResourceTrackerService`实例。

	// ResourceTrackerService实现了ResourceTracker通信接口，并启动RPC Server  
	public class ResourceTrackerService extends AbstractService implements  
	    ResourceTracker {  
	  private Server server;  
	  ...  
	  protected void serviceStart() throws Exception {  
	    super.serviceStart();  
	    Configuration conf = getConfig();  
	    YarnRPC rpc = YarnRPC.create(conf); //使用YarnRPC类  
	    this.server = rpc.getServer(ResourceTracker.class, this, resourceTrackerAddress,  
	          conf, null, conf.getInt(YarnConfiguration.RM_RESOURCE_TRACKER_CLIENT_THREAD_COUNT,  
	          YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_CLIENT_THREAD_COUNT));  
	     this.server.start();  
	  }  
	  ...  
	  @Override  
	  public RegisterNodeManagerResponse registerNodeManager(  
	      RegisterNodeManagerRequest request) throws YarnException,  
	      IOException {  
	    //具体实现  
	  }  
	  @Override  
	  public NodeHeartbeatResponse nodeHeartbeat(NodeHeartbeatRequest request)  
	      throws YarnException, IOException {  
	    //具体实现  
	  }  
	} 

#### 2、YARN `ResourceTracker`客户端 ####

同样，客户端 也是用反射机制，生成`ResourceTrackerPBClientImpl`实例，返回给YARN框架里面用，yarn框架可以透明的使用这个客户端，PB序列化过程在内部完成。

----------

### 六、总结 ###

总结就是，RPC框架加了PB序列化层，而对于YARN框架是透明的，在yarn框架里面使用协议很方便。

比如新写一个协议，要在yarn里面用，过程还是会比较繁琐。需要自己写 PB 的服务器端和客户端，对请求参数和返回值 进行进一步封装，还是相当的繁琐。

在YARN 框架里面，用`YarnRPC`类作为服务器和客户端的工厂。为了反射实现PB 的RPC服务器和客户端，有几个重要相关类。

- `YarnRPC`的实现类`HadoopYarnProtoRPC`，引用了`RpcFactoryProvider`。
- `RpcServerFactory`的实现类`RpcServerFactoryPBImpl`：生成PB RPC server。
- `RpcClientFactory`的实现类`RpcClientFactoryPBImpl`：生成PB RPC client。