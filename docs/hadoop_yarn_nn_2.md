# Hadoop YARN资源隔离技术 #

YARN对内存资源和CPU资源采用了不同的资源隔离方案。对于内存资源，它是一种限制性资源，它的量的大小直接决定应用程序的死活，因为应用程序到达内存限制，会发生OOM，就会被杀死。CPU资源一般用Cgroups进行资源控制，Cgroups控制资源测试可以参见这篇博文Cgroups控制cpu，内存，io示例，内存资源隔离除Cgroups之外提供了另外一个更灵活的方案，就是线程监控方案。

## 内存资源隔离 ##

默认情况下YARN采用线程监控的方案控制内存使用，采用这种机制的原因有两点：

1. Java创建子进程采用了“fork()+exec()”的方案，子进程启动的瞬间，它使用的内存量和父进程一致。一个进程使用的内存量可能瞬间翻倍，然后又降下来，采用线程监控的方法可防止这种情况下导致的swap操作。
2. 通常情况下，Hadoop任务运行在独立的Java虚拟机中，可以达到资源隔离的目的。Hadoop Streaming是Hadoop提供的一个编程工具，它允许用户使用任何可执行文件或者脚本文件作为Mapper和Reducer，通过Hadoop Streaming编写的MapReduce应用程序中每个任务可以由不同的编程语言环境组成，这难以通过创建单独的虚拟机达到资源隔离的效果。
 

综上，为了获取更加灵活的资源控制效果，Hadoop对内存的资源隔离采用线程监控方案。解决方案具体如下：

1. linux系统的/proc/<pid>/stat文件，实时的反应进程树使用的内存总量，可以基于此判断任务粒度的内存使用量是否超过设定的最大值。getconf PAGESIZE可以获取page大小。
2. 为了避免JVM的“fork()+exec()”模型引发的误杀操作，Hadoop赋予每个进程”年龄”属性，并规定刚启动进程的年龄是1，监控线程每更新一次，各个进程年龄加1，在此基础上，选择被杀死进程组的标准如下：如果一个进程组中所有的进程（年龄大于0）总内存超过用户设置的最大值的两倍，或者所有年龄大于1的进程总内存量超过用户设置最大值，则认为该进程组过量使用内存，就将其kill掉。
 

这种细粒度，更加灵活的线程监控资源隔离方案，还是值得学习与称道的，记录于此，以后设计系统可以参考。

## CPU资源隔离 ##

目前的CPU被划分成虚拟CPU（CPU virtual Core），这里的虚拟CPU是YARN自己引入的概念，初衷是，考虑到不同节点的CPU性能可能不同，每个CPU具有的计算能力也是不一样的，比如某个物理CPU的计算能力可能是另外一个物理CPU的2倍，这时候，你可以通过为第一个物理CPU多配置几个虚拟CPU弥补这种差异。用户提交作业时，可以指定每个任务需要的虚拟CPU个数。在YARN中，CPU相关配置参数如下：

（1）yarn.nodemanager.resource.cpu-vcores
表示该节点上YARN可使用的虚拟CPU个数，默认是8，注意，目前推荐将该值设值为与物理CPU核数数目相同。如果你的节点CPU核数不够8个，则需要调减小这个值，而YARN不会智能的探测节点的物理CPU总数。

（2） yarn.scheduler.minimum-allocation-vcores
单个任务可申请的最小虚拟CPU个数，默认是1，如果一个任务申请的CPU个数少于该数，则该对应的值改为这个数。

（3）yarn.scheduler.maximum-allocation-vcores
单个任务可申请的最多虚拟CPU个数，默认是32。
默认情况下，YARN是不会对CPU资源进行调度的，你需要配置相应的资源调度器让你支持。

参考：

《Hadoop技术内幕--深入解析YARN架构设计与实现原理》